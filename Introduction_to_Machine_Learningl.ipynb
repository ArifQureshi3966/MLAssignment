{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Machine Learningl",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP81vVQerzwn5TnNmALuZHr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArifQureshi3966/MLAssignment/blob/main/Introduction_to_Machine_Learningl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOALNEpmfG9t"
      },
      "source": [
        "# **Assignmnet 1**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYnIWw2BFtdi"
      },
      "source": [
        "**Arif Ullah Qureshi**\n",
        "\n",
        "**2017-EE-145**\n",
        "\n",
        "**Section D**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiMsIhizgpQq"
      },
      "source": [
        "# **Introduction**\n",
        "In this machine learning assignmnet I will be using the Car Evaluation Data Set from the UCI Machine Learning Repository .I will shuffle the dateset to create 3 splits of equal ratio.I will use Random Forest Classifier and Decison Tree Classifier to try to predict car acceptibility using a number of features.After training and testing of the 3 splits.I will use their average accuracy of the 2 models to determine with model is the best.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8JCATvZEEau"
      },
      "source": [
        "#Mouting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Hz1g-TD2va",
        "outputId": "613a8a8c-0aa5-4049-ab13-256af6d8dc64"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwHDgE8iCEjO"
      },
      "source": [
        "#Libraries Initialization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1EO5MFWvn4S"
      },
      "source": [
        "Initializing the necessary Python libraries.I will be using Python to solve a binary classification problem using both a decision tree as well as a random forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bicl5BS0BSsz"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import ensemble, preprocessing, model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWsnyICyCAMQ"
      },
      "source": [
        "#Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUiwMPSaMAvS"
      },
      "source": [
        "I will be using the Car Evaluation Data Set from the UCI Machine Learning Repository .I get a count of the number of unique values for each feature column in the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP5YSkSIExdG",
        "outputId": "cf960a9f-94e1-42fb-a6b4-c3e9f522d86d"
      },
      "source": [
        "dataFrame  = pd.read_csv('/content/drive/MyDrive/ML Assignmnet/Dataset/car_evaluation.csv',header=0)\n",
        "dataFrame .info()\n",
        "\n",
        "# Get a count of the number of unique values for each feature column in the DataFrame.\n",
        "feature_names = list(dataFrame.columns.values[:-1])\n",
        "for feature in feature_names:\n",
        "    unique_count = dataFrame[feature].nunique()\n",
        "    unique_vals = dataFrame[feature].unique()\n",
        "    print(\"{}: {} values, {}\".format(feature, unique_count, unique_vals))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1728 entries, 0 to 1727\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   buying    1728 non-null   object\n",
            " 1   maint     1728 non-null   object\n",
            " 2   doors     1728 non-null   object\n",
            " 3   persons   1728 non-null   object\n",
            " 4   lug_boot  1728 non-null   object\n",
            " 5   safety    1728 non-null   object\n",
            " 6   class     1728 non-null   object\n",
            "dtypes: object(7)\n",
            "memory usage: 94.6+ KB\n",
            "buying: 4 values, ['vhigh' 'high' 'med' 'low']\n",
            "maint: 4 values, ['vhigh' 'high' 'med' 'low']\n",
            "doors: 4 values, ['2' '3' '4' '5more']\n",
            "persons: 3 values, ['2' '4' 'more']\n",
            "lug_boot: 3 values, ['small' 'med' 'big']\n",
            "safety: 3 values, ['low' 'med' 'high']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgd1SYQhDJDT"
      },
      "source": [
        "#Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jeg5XqdaNhvA"
      },
      "source": [
        "The data as obtained from the UCI dataset repository have\n",
        "to be cleaned and to ensure that it is in the standard quality\n",
        "before the model creation is initiated. The data cleaning\n",
        "conducted on the dataset is the conversion of nominal attributes to numeric attributes. The nominal to numeric conversion process was conducted in order to make the process of normalization possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwkghXYv0a5_"
      },
      "source": [
        "### Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "wKswHRZl0ZTa",
        "outputId": "7d935180-5514-4384-f613-869c2e2cf582"
      },
      "source": [
        "buyingMapping = {\"low\": 1, \"med\": 2, \"high\": 3, \"vhigh\": 4}\n",
        "dataFrame[\"buying\"] = dataFrame[\"buying\"].map(buyingMapping)\n",
        "\n",
        "maintMapping = {\"low\": 1, \"med\": 2, \"high\": 3, \"vhigh\": 4}\n",
        "dataFrame[\"maint\"] = dataFrame[\"maint\"].map(maintMapping)\n",
        "\n",
        "doorsMapping = {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5}\n",
        "dataFrame[\"doors\"] = dataFrame[\"doors\"].map(doorsMapping)\n",
        "\n",
        "personsMapping = {\"2\": 2, \"4\": 4, \"more\": 6}\n",
        "dataFrame[\"persons\"] = dataFrame[\"persons\"].map(personsMapping)\n",
        "\n",
        "lugBootMapping = {\"small\": 1, \"med\": 2, \"big\": 3}\n",
        "dataFrame[\"lug_boot\"] = dataFrame[\"lug_boot\"].map(lugBootMapping)\n",
        "\n",
        "safetyMapping = {\"low\": 1, \"med\": 2, \"high\": 3}\n",
        "dataFrame[\"safety\"] = dataFrame[\"safety\"].map(safetyMapping)\n",
        "\n",
        "classMapping = {\"unacc\": 0, \"acc\": 1, \"good\": 2, \"vgood\": 3}\n",
        "dataFrame[\"class\"] = dataFrame[\"class\"].map(classMapping)\n",
        "dataFrame.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>buying</th>\n",
              "      <th>maint</th>\n",
              "      <th>doors</th>\n",
              "      <th>persons</th>\n",
              "      <th>lug_boot</th>\n",
              "      <th>safety</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1723</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1725</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1726</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1727</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      buying  maint  doors  persons  lug_boot  safety  class\n",
              "1723       1      1      5        6         2       2      2\n",
              "1724       1      1      5        6         2       3      3\n",
              "1725       1      1      5        6         3       1      0\n",
              "1726       1      1      5        6         3       2      2\n",
              "1727       1      1      5        6         3       3      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa9loJirKoHr"
      },
      "source": [
        "# Traning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESM5C7nPSfWG"
      },
      "source": [
        "Training of Random Forest and Decision tree models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sljK_VidQRoQ"
      },
      "source": [
        "Assigning the columns in the DataFrame to the features 'X' (independent variables) and labels 'y' (dependent variable)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRB9qcv029q2"
      },
      "source": [
        "# Features.\n",
        "X = dataFrame.loc[:, 'buying':'safety']\n",
        "# Labels.\n",
        "y = dataFrame.loc[:, 'class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt5yl-pTQZQR"
      },
      "source": [
        "Spliting the dataset in an 70:30 ratio for training and test set respectively for 3 different random states to create 3 different datasets.\n",
        "1. Split 1\n",
        "2. Split 2\n",
        "3. Split 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsEpEDfu3vHt"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuvyb76RGPod"
      },
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = model_selection.train_test_split(X,y,test_size=0.3,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKlP6isLHmpi"
      },
      "source": [
        "X_train3, X_test3, y_train3, y_test3 = model_selection.train_test_split(X,y,test_size=0.3,random_state=21)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iOslLH34pwu"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q6WKzk7ST0p"
      },
      "source": [
        "\n",
        "I will be using a random forest classifier, which is an ensemble of individial decision tree classifiers.\n",
        "\n",
        "Creating the Random forest classifier using 500 decision trees.Each decision tree created by the random forest classifier algorithm trains on a random sample from the data and on random features. The algorithm takes the classifications made by each of these trees, and the one with most votes is the final prediction of the random forest algorithm. This ensemble approach improves the accuracy of the final overall classification and helps minimise the chances of an overfitted model.The random forest algorithm is fast, can work with large datasets and maintains its accuracy despite missing data, but unlike a single decision tree it is difficult to interpret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFQVZTvL45Jp"
      },
      "source": [
        "##### Random Forest for Split 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ffdrzm15IkX",
        "outputId": "3c3866ad-183d-409e-89ba-d0443042aa25"
      },
      "source": [
        "Rclf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
        "# Training the classifier. This is where the forest of decision trees are created.\n",
        "Rclf.fit(X_train, y_train)\n",
        "A1 = Rclf.score(X_test,y_test)\n",
        "y_pred = Rclf.predict(X_test)\n",
        "print(\"Accuracy for split 1 using random forest is: {0:0.4f} \".format(A1*100),\"%\")\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "Rclf.fit(X_train_scaled,y_train)\n",
        "AS1 = Rclf.score(X_test_scaled,y_test)\n",
        "print(\"Accuracy for split 1 using random forest when data is scaled between the maximum and minimum: {0:0.4f} \".format(AS1*100),\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for split 1 using random forest is: 96.5318  %\n",
            "Accuracy for split 1 using random forest when data is scaled between the maximum and minimum: 96.3391  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZMEeeAfUG7E"
      },
      "source": [
        "##### Random Forest for Split 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQOJFX24xfau",
        "outputId": "77fd1087-0948-42c8-bad5-199307996ccd"
      },
      "source": [
        "Rclf2 = RandomForestClassifier(n_estimators=500, random_state=0)\n",
        "# Training the classifier. This is where the forest of decision trees are created.\n",
        "Rclf2.fit(X_train2, y_train2)\n",
        "A2 = Rclf2.score(X_test2,y_test2)\n",
        "y_pred2 = Rclf2.predict(X_test2)\n",
        "print(\"Accuracy for split 2 using random forest is: {0:0.4f} \".format(A2*100),\"%\")\n",
        "scaler2 = preprocessing.MinMaxScaler()\n",
        "X_train_scaled2 = scaler2.fit_transform(X_train2)\n",
        "X_test_scaled2 = scaler2.fit_transform(X_test2)\n",
        "Rclf2.fit(X_train_scaled2,y_train2)\n",
        "AS2 = Rclf2.score(X_test_scaled2,y_test2)\n",
        "print(\"Accuracy for split 2 using random forest when data is scaled between the maximum and minimum: {0:0.4f} \".format(AS2*100),\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for split 2 using random forest is: 98.0732  %\n",
            "Accuracy for split 2 using random forest when data is scaled between the maximum and minimum: 98.0732  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W27p4jG2UJqK"
      },
      "source": [
        "##### Random Forest for Split 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83Iy5G8xIDQk",
        "outputId": "32027fea-4680-4022-d9cc-c1cbcc6931c5"
      },
      "source": [
        "Rclf3 = RandomForestClassifier(n_estimators=500, random_state=21)\n",
        "# Training the classifier. This is where the forest of decision trees are created.\n",
        "Rclf3.fit(X_train3, y_train3)\n",
        "A3 = Rclf3.score(X_test3,y_test3)\n",
        "y_pred3 = Rclf3.predict(X_test3)\n",
        "print(\"Accuracy for split 3 using random forest is: {0:0.4f} \".format(A3*100),\"%\")\n",
        "scaler3 = preprocessing.MinMaxScaler()\n",
        "X_train_scaled3 = scaler3.fit_transform(X_train3)\n",
        "X_test_scaled3 = scaler3.fit_transform(X_test3)\n",
        "Rclf3.fit(X_train_scaled3,y_train3)\n",
        "AS3 = Rclf3.score(X_test_scaled3,y_test3)\n",
        "print(\"Accuracy for split 3 using random forest when data is scaled between the maximum and minimum: {0:0.4f} \".format(AS3*100),\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for split 3 using random forest is: 97.6879  %\n",
            "Accuracy for split 3 using random forest when data is scaled between the maximum and minimum: 97.8805  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M12nzZKUWAEa"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWUjb74HW3qI"
      },
      "source": [
        "A decision tree is a simple tree-like structure constituting nodes and branches.At each step, a decision is made based on the attribute in question, and the result generates a branch of the tree. Using this divide and conquer classification rules are generated. The rule is a path from the Root node to an End node. An advantage of Decision Tree is that the Information gained can be used in feature selection as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mygrhD-SGBLb"
      },
      "source": [
        "##### Decision Tree for Split 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWn2y_oaEgxN",
        "outputId": "9c59cdc7-5bb6-45d3-aca6-50f5690fa6b2"
      },
      "source": [
        "Dtree1 = DecisionTreeClassifier(criterion = 'entropy', random_state=42).fit(X_train,y_train)\n",
        "y_predic1 = Dtree1.predict(X_test)\n",
        "AD1 = Dtree1.score(X_test,y_test)\n",
        "print(\"Accuracy for split 1 using Decision Trees is: {0:0.4f} \".format(AD1*100),\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for split 1 using Decision Trees is: 96.9171  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-T4hFqMG7iS"
      },
      "source": [
        "##### Decision Tree for Split 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAm3M6S_G7G2",
        "outputId": "4f6787a4-259d-4a95-a7f8-5142de800d3a"
      },
      "source": [
        "Dtree2 = DecisionTreeClassifier(criterion = 'entropy', random_state=0).fit(X_train2,y_train2)\n",
        "y_predic2 = Dtree2.predict(X_test2)\n",
        "AD2 = Dtree2.score(X_test2,y_test2)\n",
        "print(\"Accuracy for split 2 using Decision Trees is: {0:0.4f} \".format(AD2*100),\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for split 2 using Decision Trees is: 98.2659  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDU-Xu1UJNiW"
      },
      "source": [
        "##### Decision Tree for Split 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwpaah8nJQop",
        "outputId": "aa2922b7-70ef-4479-ac56-ae4feef2d572"
      },
      "source": [
        "Dtree3 = DecisionTreeClassifier(criterion = 'entropy',random_state=21).fit(X_train3,y_train3)\n",
        "y_predic3 = Dtree3.predict(X_test3)\n",
        "AD3 = Dtree3.score(X_test3,y_test3)\n",
        "print(\"Accuracy for split 3 using Decision Trees is: {0:0.4f} \".format(AD3*100),\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for split 3 using Decision Trees is: 96.7245  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSGkHmUtK-rK"
      },
      "source": [
        "# Average Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqCFjYrNLmN3"
      },
      "source": [
        "### Average Accuracy of Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhFdN21FLk_Q",
        "outputId": "6e0bf30f-5a63-401a-8629-313fe4d75089"
      },
      "source": [
        "Avg_Acc1 = (A1+A2+A3)/3\n",
        "print('Average accuracy using Random Forest : {0:0.4f}'. format(Avg_Acc1*100),\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average accuracy using Random Forest : 97.4310 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTyNrlMsODkv"
      },
      "source": [
        "### Average Accuracy of Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7F-jy05N1zW",
        "outputId": "12400243-c7fa-4ab8-ea12-4dec845c5357"
      },
      "source": [
        "Avg_Acc = (AD1+AD2+AD3)/3\n",
        "print('Average accuracy using Decision Tree Classifier: {0:0.4f}'. format(Avg_Acc*100),\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average accuracy using Decision Tree Classifier: 97.3025 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwxeJ54VkfEz"
      },
      "source": [
        "Accuracy of the Random Forest Classifier is slightly greater than the Decision Tree Classifier.So Random Forest performs better for this dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPT6gDo6OV0A"
      },
      "source": [
        "# Confusion matrices and Classifcation Report\n",
        "The Confusion-matrix yields the most ideal suite of metrics for evaluating the performance of a classification algorithm such as Decision tree  and Random Forest. A confusion matrix is a summary of prediction results on a classification problem.The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n",
        "\n",
        "Given an array or list of expected values and a list of predictions from your machine learning model, the confusion_matrix() function will calculate a confusion matrix and return the result as an array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yau0JNS4WW3d"
      },
      "source": [
        "## Using Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPK8IXiXqy18"
      },
      "source": [
        "##### Split 1 Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxnQ7U1nOfMv",
        "outputId": "d367816a-dc62-4f71-d73e-979fd3dbfbf5"
      },
      "source": [
        "cm1= confusion_matrix(y_test,y_pred)\n",
        "print('Confusion matrix on split 1 using random forest \\n\\n', cm1)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix on split 1 using random forest \n",
            "\n",
            " [[355   3   0   0]\n",
            " [  2 108   6   2]\n",
            " [  0   1  17   1]\n",
            " [  0   3   0  21]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       358\n",
            "           1       0.94      0.92      0.93       118\n",
            "           2       0.74      0.89      0.81        19\n",
            "           3       0.88      0.88      0.88        24\n",
            "\n",
            "    accuracy                           0.97       519\n",
            "   macro avg       0.89      0.92      0.90       519\n",
            "weighted avg       0.97      0.97      0.97       519\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LcAIGVgq84U"
      },
      "source": [
        "##### Split 2 Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61pXk0G2XV-q",
        "outputId": "fc4481d6-1f16-404f-e6be-7fceb986e597"
      },
      "source": [
        "cm2=confusion_matrix(y_test2,y_pred2)\n",
        "print('Confusion matrix on split 2 using random forest \\n\\n', cm2)\n",
        "print(classification_report(y_test2, y_pred2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix on split 2 using random forest \n",
            "\n",
            " [[361   2   0   0]\n",
            " [  1 112   2   0]\n",
            " [  0   0  23   2]\n",
            " [  0   3   0  13]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       363\n",
            "           1       0.96      0.97      0.97       115\n",
            "           2       0.92      0.92      0.92        25\n",
            "           3       0.87      0.81      0.84        16\n",
            "\n",
            "    accuracy                           0.98       519\n",
            "   macro avg       0.94      0.93      0.93       519\n",
            "weighted avg       0.98      0.98      0.98       519\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhgTZ0DErJoO"
      },
      "source": [
        "##### Split 3 Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8m-akNHX9aF",
        "outputId": "c0bd4ecb-8348-4ae7-8323-9f00c74dda88"
      },
      "source": [
        "cm3=confusion_matrix(y_test3,y_pred3)\n",
        "print('Confusion matrix on split 3 using random forest \\n\\n', cm3)\n",
        "print(classification_report(y_test3, y_pred3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix on split 3 using random forest \n",
            "\n",
            " [[345   1   0   0]\n",
            " [  2 133   1   0]\n",
            " [  0   2  17   2]\n",
            " [  0   4   0  12]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       346\n",
            "           1       0.95      0.98      0.96       136\n",
            "           2       0.94      0.81      0.87        21\n",
            "           3       0.86      0.75      0.80        16\n",
            "\n",
            "    accuracy                           0.98       519\n",
            "   macro avg       0.94      0.88      0.91       519\n",
            "weighted avg       0.98      0.98      0.98       519\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FATg_49wYplk"
      },
      "source": [
        "## Using Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ-1cZbErkFu"
      },
      "source": [
        "##### All Data Splits Confusion Matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxKm_ZZ6YuyT",
        "outputId": "48ee94d7-ffc6-45ba-c8f4-9c859c5e1d2c"
      },
      "source": [
        "cm1dt = confusion_matrix(y_test, y_predic1)\n",
        "cm2dt = confusion_matrix(y_test2, y_predic2)\n",
        "cm3dt = confusion_matrix(y_test3, y_predic3)\n",
        "print('Confusion matrix on split 1 using Decision Trees\\n\\n', cm1dt)\n",
        "print(classification_report(y_test, y_predic1))\n",
        "print('Confusion matrix on split 2 using Decision Trees\\n\\n', cm2dt)\n",
        "print(classification_report(y_test2, y_predic2))\n",
        "print('Confusion matrix on split 3 using Decision Trees\\n\\n', cm3dt)\n",
        "print(classification_report(y_test3, y_predic3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix on split 1 using Decision Trees\n",
            "\n",
            " [[358   0   0   0]\n",
            " [  3 109   5   1]\n",
            " [  0   1  17   1]\n",
            " [  0   3   2  19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       358\n",
            "           1       0.96      0.92      0.94       118\n",
            "           2       0.71      0.89      0.79        19\n",
            "           3       0.90      0.79      0.84        24\n",
            "\n",
            "    accuracy                           0.97       519\n",
            "   macro avg       0.89      0.90      0.89       519\n",
            "weighted avg       0.97      0.97      0.97       519\n",
            "\n",
            "Confusion matrix on split 2 using Decision Trees\n",
            "\n",
            " [[362   1   0   0]\n",
            " [  2 109   4   0]\n",
            " [  0   1  24   0]\n",
            " [  0   1   0  15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       363\n",
            "           1       0.97      0.95      0.96       115\n",
            "           2       0.86      0.96      0.91        25\n",
            "           3       1.00      0.94      0.97        16\n",
            "\n",
            "    accuracy                           0.98       519\n",
            "   macro avg       0.96      0.96      0.96       519\n",
            "weighted avg       0.98      0.98      0.98       519\n",
            "\n",
            "Confusion matrix on split 3 using Decision Trees\n",
            "\n",
            " [[344   2   0   0]\n",
            " [  5 128   1   2]\n",
            " [  0   0  18   3]\n",
            " [  0   4   0  12]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       346\n",
            "           1       0.96      0.94      0.95       136\n",
            "           2       0.95      0.86      0.90        21\n",
            "           3       0.71      0.75      0.73        16\n",
            "\n",
            "    accuracy                           0.97       519\n",
            "   macro avg       0.90      0.89      0.89       519\n",
            "weighted avg       0.97      0.97      0.97       519\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHWuc0I5wE2F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tl30bEHeYu9"
      },
      "source": [
        "#Statistical analysis using TTest\n",
        "Statistical Testing with Paired T-Test —  According to given dataset, I have only one dataset but I have used multiple folds of the same dataset to evaluate the accuracies.I need to use a test which can test the model’s accuracies on multiple folds of single datasets. The Paired T-Test would most suitable statistical test for this purpose.\n",
        "\n",
        "For all the 3 folds, the accuracy difference is very very minute. This represents both models are performing almost the same. I need to use statistical testing to resolve this doubt.\n",
        "\n",
        "We need a threshold, alpha to find out the statistical difference. Here’s the deal with the alpha.\n",
        "\n",
        "\n",
        "\n",
        "*  If p > alpha - > then there's no significance difference between two models\n",
        "*  If p < alpha -> then there is significance difference between two models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pnV-juXb63a",
        "outputId": "c8661373-a650-4f07-e8f3-12fafe2ab520"
      },
      "source": [
        "import numpy as np\n",
        "RF_model=np.array([A1,A2,A3])\n",
        "DT_model=np.array([AD1,AD2,AD3])\n",
        "print(np.var(RF_model),np.var(DT_model))\n",
        "import scipy.stats as stats\n",
        "stats.ttest_ind(a=RF_model,b=DT_model,equal_var=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.289988363406576e-05 4.702487244503292e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=0.19156525704422148, pvalue=0.8574140036991883)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwNpK7cE1mvK"
      },
      "source": [
        "Since the difference between the accuracies is very very low, I need a greater alpha to find out the difference. So, alpha = 0.5, is significant to show the difference for my problem and since p > alpha so then there's no significance difference between two models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxinYpooECzF"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtLCZQFCjlA5"
      },
      "source": [
        "## Why Did Our Random Forest Model Outperform the Decision Tree?\n",
        "Our decision tree model is overfitting on the training data.The decision tree model gives high importance to a particular set of features. But the random forest chooses features randomly during the training process. Therefore, it does not depend highly on any specific set of features.\n",
        "Random Forest is suitable for situations when we have a large dataset, and interpretability is not a major concern.Therefore, the random forest can generalize over the data in a better way. This randomized feature selection makes random forest much more accurate than a decision tree.\n",
        "\n",
        "Reference Link: [Link](https://www.analyticsvidhya.com/blog/2020/05/decision-tree-vs-random-forest-algorithm/#:~:text=Each%20node%20in%20the%20decision,to%20generate%20the%20final%20output.&text=The%20Random%20Forest%20Algorithm%20combines,to%20generate%20the%20final%20output.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TljBQ64q2Wk"
      },
      "source": [
        "## Why Choose Random Forest and Not Decision Trees?\n",
        "\n",
        "Random forest works well with non-linear data, has lower risk of overfitting,runs efficiently on a large dataset and also has Better accuracy than other classification algorithms.\n",
        "\n",
        "While the decision tree are prone to overfitting.It can be quite large, thus making pruning necessary.It can’t guarantee optimal trees.It gives low prediction accuracy for a dataset as compared to other machine learning algorithms.Calculations can become complex when there are many class variables.\n",
        "\n",
        "Reference Link: [Link](https://towardsai.net/p/machine-learning/why-choose-random-forest-and-not-decision-trees)"
      ]
    }
  ]
}